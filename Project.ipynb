{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncovering the Liars in the Political Scene of America\n",
    "\n",
    "This notebook will present a data analysis task on the \"Liar, Liar Pants on Fire\" dataset, available for download [there](https://www.cs.ucsb.edu/Ëœwilliam/data/liar_dataset.zip), in the framework of a project for the class \"Applied Data Analysis\" at EPFL.\n",
    "\n",
    "### Table of contents:\n",
    "* [Loading phase](#loading-phase)\n",
    "* [Cleaning phase](#cleaning-phase)\n",
    "* [Loading additional files](#loading-additional-files)\n",
    "* [Data analysis](#data-analysis)\n",
    "    * [Relative importance of each feature](#relative-importance)\n",
    "    * [Map visualization](#map-visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import folium\n",
    "import ipywidgets as ipw\n",
    "import html\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading phase <a class=\"anchor\" id=\"loading-phase\"></a>\n",
    "\n",
    "The liar dataset is composed of three different datasets, namely `test.tsv`, `train.tsv` and `valid.tsv`, which we first load into Pandas dataframes with corresponding names. All of these datasets have exactly the same schema. The purpose of having three different datasets is to do machine learning, which is not the goal of this project. In consequence, we will combine all three dataframes `test`, `train` and `valid` into a single one, `liar`.\n",
    "\n",
    "The schema of these datasets is outlined below. There is a total of 14 columns and each row refers to a statement.\n",
    "\n",
    "> Column 1: ID of the statement ([ID].json).\n",
    "> \n",
    "> Column 2: Label.\n",
    "> \n",
    "> Column 3: Statement.\n",
    "> \n",
    "> Column 4: Subject(s).\n",
    "> \n",
    "> Column 5: Speaker.\n",
    "> \n",
    "> Column 6: Speaker's job title.\n",
    "> \n",
    "> Column 7: State info.\n",
    "> \n",
    "> Column 8: Party affiliation.\n",
    "> \n",
    "> Column 9: Barely true counts.\n",
    "> \n",
    "> Column 10: False counts.\n",
    "> \n",
    "> Column 11: Half true counts.\n",
    "> \n",
    "> Column 12: Mostly true counts.\n",
    "> \n",
    "> Column 13: Pants on fire counts.\n",
    "> \n",
    "> Column 14: Context (venue / location of the speech or statement).\n",
    "\n",
    "In order to reduce the size of the dataframe, we could drop the columns which we do not need. Note that this is not required because the dataset is rather small, but could be done simply for the sake of convenience. However, we will probably need all columns, so no action will be taken there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data/'\n",
    "SCHEMA = ['statement_id', 'label', 'statement', 'subject', \n",
    "          'speaker', 'profession', 'state', 'party', \n",
    "          'barely_true', 'false', 'half_true', \n",
    "          'mostly_true', 'pants_on_fire', 'context']\n",
    "\n",
    "# Load the datasets into pandas dataframes\n",
    "test = pd.read_csv(DATA_DIR + 'test.tsv', delimiter='\\t', header=None, names=SCHEMA, index_col=False)\n",
    "train = pd.read_csv(DATA_DIR + 'train.tsv', delimiter='\\t', header=None, names=SCHEMA, index_col=False)\n",
    "valid = pd.read_csv(DATA_DIR + 'valid.tsv', delimiter='\\t', header=None, names=SCHEMA, index_col=False)\n",
    "\n",
    "\n",
    "# Combine the three dataframes into one\n",
    "liar = pd.concat([train, test, valid], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement_id</th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>profession</th>\n",
       "      <th>state</th>\n",
       "      <th>party</th>\n",
       "      <th>barely_true</th>\n",
       "      <th>false</th>\n",
       "      <th>half_true</th>\n",
       "      <th>mostly_true</th>\n",
       "      <th>pants_on_fire</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2635.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a mailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10540.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>energy,history,job-accomplishments</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>State delegate</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a floor speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324.json</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>foreign-policy</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Denver</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  statement_id        label  \\\n",
       "0    2635.json        false   \n",
       "1   10540.json    half-true   \n",
       "2     324.json  mostly-true   \n",
       "\n",
       "                                           statement  \\\n",
       "0  Says the Annies List political group supports ...   \n",
       "1  When did the decline of coal start? It started...   \n",
       "2  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "\n",
       "                              subject         speaker            profession  \\\n",
       "0                            abortion    dwayne-bohac  State representative   \n",
       "1  energy,history,job-accomplishments  scott-surovell        State delegate   \n",
       "2                      foreign-policy    barack-obama             President   \n",
       "\n",
       "      state       party  barely_true  false  half_true  mostly_true  \\\n",
       "0     Texas  republican          0.0    1.0        0.0          0.0   \n",
       "1  Virginia    democrat          0.0    0.0        1.0          1.0   \n",
       "2  Illinois    democrat         70.0   71.0      160.0        163.0   \n",
       "\n",
       "   pants_on_fire          context  \n",
       "0            0.0         a mailer  \n",
       "1            0.0  a floor speech.  \n",
       "2            9.0           Denver  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the dataframe\n",
    "liar.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check that the three datasets are different (which they should based on their purpose):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liar['statement_id'].is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning phase <a class=\"anchor\" id=\"cleaning-phase\"></a>\n",
    "\n",
    "This dataset id very clean by nature because it is not just a collection of data. Indeed, it was intended for use by other data scientists as a benchmark dataset and it will therefore not need many data cleaning operations. We can start by checking if every row is complete or if there are any NaNs or missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "statement_id     False\n",
       "label            False\n",
       "statement        False\n",
       "subject           True\n",
       "speaker           True\n",
       "profession        True\n",
       "state             True\n",
       "party             True\n",
       "barely_true       True\n",
       "false             True\n",
       "half_true         True\n",
       "mostly_true       True\n",
       "pants_on_fire     True\n",
       "context           True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liar.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that most of the columns, more precisely column 4 to 15, do have missing values. However, we will not drop every row where there are NaNs because the other fields in these rows might still be useful. In consequence, we will only drop rows containing solely NaNs (if any) and deal with missing values later on when required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before dropping \"all Nans\" rows: 12791\n",
      "Number of rows after  dropping \"all Nans\" rows: 12791\n"
     ]
    }
   ],
   "source": [
    "# Number of rows before dropping \"all Nans\" rows\n",
    "print('Number of rows before dropping \"all Nans\" rows: %s'%liar.shape[0])\n",
    "\n",
    "liar = liar.dropna(how='all')\n",
    "\n",
    "# Number of rows before dropping \"all Nans\" rows\n",
    "print('Number of rows after  dropping \"all Nans\" rows: %s'%liar.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No rows were dropped with this data cleaning operation, meaning that all rows had at least one valid value.\n",
    "\n",
    "We will now investigate how the data is formatted to check for potential inconcistencies. We can start with the column concerning the state where the statement was made, because we can have a fairly good idea of what it should contain (i.e. names of locations like states or countries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Texas', 'Virginia', 'Illinois', nan, 'Florida', 'Wisconsin',\n",
       "       'New Jersey', 'Vermont', 'Massachusetts', 'Maryland',\n",
       "       'Washington, D.C. ', 'Oregon', 'New York', 'Washington, D.C.',\n",
       "       'California', 'Missouri', 'Rhode Island', 'West Virginia',\n",
       "       'Arkansas', 'New Hampshire', 'Ohio', 'Georgia', 'Arizona',\n",
       "       'Wyoming', 'Delaware', 'Kentucky', 'Kansas', 'ohio', 'Colorado',\n",
       "       'North Carolina', 'New Mexico', 'Illinois ', 'Alaska',\n",
       "       'South Carolina', 'Minnesota', 'Tennessee', 'Pennsylvania', 'Iowa',\n",
       "       'Connecticut', 'Louisiana', 'Indiana', 'Florida ', 'Utah',\n",
       "       'Michigan', 'Oklahoma', 'Nevada', 'Oregon ', 'Virgina', 'Nebraska',\n",
       "       'Georgia ', 'None', 'Washington D.C.', 'California ',\n",
       "       'Massachusetts ', 'Alabama', 'Russia', 'Washington state',\n",
       "       'Washington', 'District of Columbia', 'Unknown', 'Colorado ',\n",
       "       'New Hampshire ', 'Mississippi', 'Rhode island', 'China',\n",
       "       'United Kingdom', 'Virginia ', 'South Dakota', 'Qatar', 'Montana',\n",
       "       'North Dakota', 'Idaho', 'Maine', 'New York ',\n",
       "       'Virginia director, Coalition to Stop Gun Violence', 'Virgiia',\n",
       "       'Hawaii', 'Atlanta', 'Tennesse', 'Washington DC', 'Wisconsin ',\n",
       "       'PA - Pennsylvania', 'Tex', 'the United States', 'Rhode Island ',\n",
       "       'Georgia  '], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liar.state.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are inconcistencies in the use of upper case (e.g. `Ohio` and `ohio`) and problems with trailing spaces (e.g. `Georgia` and `Georgia  `). We can take care of these issues by making everything lower case and removing leading and trailing spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(s):\n",
    "    '''\n",
    "    Replaces upper case letters by lower case ones and removes leading and trailing spaces.\n",
    "    :param s: str\n",
    "    :return: s\n",
    "    '''\n",
    "    if isinstance(s, str):\n",
    "        s = s.lower()\\\n",
    "             .strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique entities in \"state\" before applying \"clean\": 86\n",
      "Number of unique entities in \"state\" after  applying \"clean\": 70\n"
     ]
    }
   ],
   "source": [
    "# Number of rows before dropping \"all Nans\" rows\n",
    "print('Number of unique entities in \"state\" before applying \"clean\": %s'%liar.state.unique().shape[0])\n",
    "\n",
    "liar['state'] = liar['state'].apply(clean)\n",
    "\n",
    "# Number of rows before dropping \"all Nans\" rows\n",
    "print('Number of unique entities in \"state\" after  applying \"clean\": %s'%liar.state.unique().shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are still other issues with the data, but we will not take care of them. For example, there are spelling mistakes (e.g. `virgiia` instead of `virginia`). We will ignore them because we can assume that these spelling mistakes will concern only one statement, which means it is not worth taking the time to take care of that kind of issues.\n",
    "\n",
    "In order to clean the other columns in liar, we will use the same function as above, `clean`. We can indeed assume that they might suffer from the same inconsistencies. It is important to point out that we will not touch to the column `statement` because we want to keep all statements as they were originally written. If we were to modify them, then all conclusions from the analysis of the statements themselves would loose credibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in liar.columns:\n",
    "    if not (col_name == 'statement'):\n",
    "        liar[col_name] = liar[col_name].apply(clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now take a final look at our cleaned `liar` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement_id</th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>profession</th>\n",
       "      <th>state</th>\n",
       "      <th>party</th>\n",
       "      <th>barely_true</th>\n",
       "      <th>false</th>\n",
       "      <th>half_true</th>\n",
       "      <th>mostly_true</th>\n",
       "      <th>pants_on_fire</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2635.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>state representative</td>\n",
       "      <td>texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a mailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10540.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>energy,history,job-accomplishments</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>state delegate</td>\n",
       "      <td>virginia</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a floor speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324.json</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>foreign-policy</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>president</td>\n",
       "      <td>illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>denver</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  statement_id        label  \\\n",
       "0    2635.json        false   \n",
       "1   10540.json    half-true   \n",
       "2     324.json  mostly-true   \n",
       "\n",
       "                                           statement  \\\n",
       "0  Says the Annies List political group supports ...   \n",
       "1  When did the decline of coal start? It started...   \n",
       "2  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "\n",
       "                              subject         speaker            profession  \\\n",
       "0                            abortion    dwayne-bohac  state representative   \n",
       "1  energy,history,job-accomplishments  scott-surovell        state delegate   \n",
       "2                      foreign-policy    barack-obama             president   \n",
       "\n",
       "      state       party  barely_true  false  half_true  mostly_true  \\\n",
       "0     texas  republican          0.0    1.0        0.0          0.0   \n",
       "1  virginia    democrat          0.0    0.0        1.0          1.0   \n",
       "2  illinois    democrat         70.0   71.0      160.0        163.0   \n",
       "\n",
       "   pants_on_fire          context  \n",
       "0            0.0         a mailer  \n",
       "1            0.0  a floor speech.  \n",
       "2            9.0           denver  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the dataframe\n",
    "liar.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading additional files <a class=\"anchor\" id=\"loading-additional-files\"></a>\n",
    "\n",
    "In order to create maps using folium displaying content from the `liar` dataframe, a new column with the abbreviations of the states will be added. The pairs state name/abbreviations are all contained in the file `states_abbreviation.csv`, which can be downloaded [here](http://www.fonz.net/blog/archives/2008/04/06/csv-of-states-and-state-abbreviations/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the file 'states_abbreviation.csv' into a dataframe\n",
    "states_abbreviation = pd.read_csv(DATA_DIR + 'states_abbreviation.csv')\n",
    "\n",
    "# Make sure we have the same format than in liar\n",
    "states_abbreviation['State'] = states_abbreviation['State'].apply(clean)\n",
    "\n",
    "i = 0\n",
    "for state_name in liar['state']:\n",
    "    temp = states_abbreviation.Abbreviation[state_name==states_abbreviation.State].values\n",
    "    if temp.size != 0:\n",
    "        liar.at[i, 'state_abbreviation'] = temp[0]\n",
    "    else:\n",
    "        liar.at[i, 'state_abbreviation'] = np.nan\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement_id</th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>profession</th>\n",
       "      <th>state</th>\n",
       "      <th>party</th>\n",
       "      <th>barely_true</th>\n",
       "      <th>false</th>\n",
       "      <th>half_true</th>\n",
       "      <th>mostly_true</th>\n",
       "      <th>pants_on_fire</th>\n",
       "      <th>context</th>\n",
       "      <th>state_abbreviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2635.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>state representative</td>\n",
       "      <td>texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a mailer</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10540.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>energy,history,job-accomplishments</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>state delegate</td>\n",
       "      <td>virginia</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a floor speech.</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324.json</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>foreign-policy</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>president</td>\n",
       "      <td>illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>denver</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  statement_id        label  \\\n",
       "0    2635.json        false   \n",
       "1   10540.json    half-true   \n",
       "2     324.json  mostly-true   \n",
       "\n",
       "                                           statement  \\\n",
       "0  Says the Annies List political group supports ...   \n",
       "1  When did the decline of coal start? It started...   \n",
       "2  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "\n",
       "                              subject         speaker            profession  \\\n",
       "0                            abortion    dwayne-bohac  state representative   \n",
       "1  energy,history,job-accomplishments  scott-surovell        state delegate   \n",
       "2                      foreign-policy    barack-obama             president   \n",
       "\n",
       "      state       party  barely_true  false  half_true  mostly_true  \\\n",
       "0     texas  republican          0.0    1.0        0.0          0.0   \n",
       "1  virginia    democrat          0.0    0.0        1.0          1.0   \n",
       "2  illinois    democrat         70.0   71.0      160.0        163.0   \n",
       "\n",
       "   pants_on_fire          context state_abbreviation  \n",
       "0            0.0         a mailer                 TX  \n",
       "1            0.0  a floor speech.                 VA  \n",
       "2            9.0           denver                 IL  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the dataframe\n",
    "liar.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will also load two additional datasets, `pop-urban-pct-historical.xls` and `federalelections2016.xlsx`, which will have the purpose of highlighting potential explanations for the distribution of fake news across America. They are available for download respectively [there](https://www.icip.iastate.edu/tables/population/urban-pct-states) and [there](https://transition.fec.gov/pubrec/electionresults.shtml). For the same reason as earlier, we will add a column with the abbreviations of the states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pop-urban-pct-historical.xls\n",
    "states_urban = pd.read_excel(DATA_DIR + 'pop-urban-pct-historical.xls', sheet_name='States',\n",
    "                             header=5, usecols='B:G,I:M,O:P')\n",
    "states_urban = states_urban[1:52]\n",
    "\n",
    "# Make sure we have the same format than in states_abbreviation\n",
    "states_urban['Area Name'] = states_urban['Area Name'].apply(clean)\n",
    "\n",
    "# Add the states abbreviations\n",
    "i = 1\n",
    "for state_name in states_urban['Area Name']:\n",
    "    temp = states_abbreviation.Abbreviation[state_name==states_abbreviation.State].values\n",
    "    if temp.size != 0:\n",
    "        states_urban.at[i, 'state_abbreviation'] = temp[0]\n",
    "    else:\n",
    "        states_urban.at[i, 'state_abbreviation'] = np.nan\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area Name</th>\n",
       "      <th>1900</th>\n",
       "      <th>1910</th>\n",
       "      <th>1920</th>\n",
       "      <th>1930</th>\n",
       "      <th>1940</th>\n",
       "      <th>1950</th>\n",
       "      <th>1960</th>\n",
       "      <th>1970</th>\n",
       "      <th>1980</th>\n",
       "      <th>1990</th>\n",
       "      <th>2000</th>\n",
       "      <th>2010</th>\n",
       "      <th>state_abbreviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alabama</td>\n",
       "      <td>11.9</td>\n",
       "      <td>17.3</td>\n",
       "      <td>21.7</td>\n",
       "      <td>28.1</td>\n",
       "      <td>30.2</td>\n",
       "      <td>43.8</td>\n",
       "      <td>54.8</td>\n",
       "      <td>58.6</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.4</td>\n",
       "      <td>55.4</td>\n",
       "      <td>59.0</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alaska</td>\n",
       "      <td>24.5</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5.6</td>\n",
       "      <td>13.2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>37.9</td>\n",
       "      <td>56.9</td>\n",
       "      <td>64.3</td>\n",
       "      <td>67.5</td>\n",
       "      <td>65.6</td>\n",
       "      <td>66.0</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arizona</td>\n",
       "      <td>15.9</td>\n",
       "      <td>31.0</td>\n",
       "      <td>36.1</td>\n",
       "      <td>34.4</td>\n",
       "      <td>34.8</td>\n",
       "      <td>55.5</td>\n",
       "      <td>74.5</td>\n",
       "      <td>79.6</td>\n",
       "      <td>83.8</td>\n",
       "      <td>87.5</td>\n",
       "      <td>88.2</td>\n",
       "      <td>89.8</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Area Name  1900  1910  1920  1930  1940  1950  1960  1970  1980  1990  2000  \\\n",
       "1   alabama  11.9  17.3  21.7  28.1  30.2  43.8  54.8  58.6  60.0  60.4  55.4   \n",
       "2    alaska  24.5   9.5   5.6  13.2  24.0  26.6  37.9  56.9  64.3  67.5  65.6   \n",
       "3   arizona  15.9  31.0  36.1  34.4  34.8  55.5  74.5  79.6  83.8  87.5  88.2   \n",
       "\n",
       "   2010 state_abbreviation  \n",
       "1  59.0                 AL  \n",
       "2  66.0                 AK  \n",
       "3  89.8                 AZ  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the dataframe\n",
    "states_urban.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load federalelections2016.xlsx\n",
    "states_election = pd.read_excel(DATA_DIR + 'federalelections2016.xlsx', sheet_name=15,\n",
    "                                header=6, usecols='A:B,E,H,K,N,Q')\n",
    "states_election = states_election[1:52]\n",
    "states_election = states_election.rename(columns={\"CLINTON\": 2016, \"OBAMA\": 2012,\n",
    "                                                  \"OBAMA.1\": 2008, \"KERRY\": 2004,\n",
    "                                                  \"GORE\": 2000, \"CLINTON.1\": 1996})\n",
    "\n",
    "# Make sure we have the same format than in states_abbreviation\n",
    "states_election['STATE'] = states_election['STATE'].apply(clean)\n",
    "\n",
    "# Add the states abbreviations\n",
    "i = 1\n",
    "for state_name in states_election['STATE']:\n",
    "    temp = states_abbreviation.Abbreviation[state_name==states_abbreviation.State].values\n",
    "    if temp.size != 0:\n",
    "        states_election.at[i, 'state_abbreviation'] = temp[0]\n",
    "    else:\n",
    "        states_election.at[i, 'state_abbreviation'] = np.nan\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>2016</th>\n",
       "      <th>2012</th>\n",
       "      <th>2008</th>\n",
       "      <th>2004</th>\n",
       "      <th>2000</th>\n",
       "      <th>1996</th>\n",
       "      <th>state_abbreviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alabama</td>\n",
       "      <td>0.343579</td>\n",
       "      <td>0.38359</td>\n",
       "      <td>0.3874</td>\n",
       "      <td>0.3684</td>\n",
       "      <td>41.57</td>\n",
       "      <td>43.16</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alaska</td>\n",
       "      <td>0.365509</td>\n",
       "      <td>0.408127</td>\n",
       "      <td>0.3789</td>\n",
       "      <td>0.3552</td>\n",
       "      <td>27.67</td>\n",
       "      <td>33.27</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arizona</td>\n",
       "      <td>0.45126</td>\n",
       "      <td>0.445898</td>\n",
       "      <td>0.4512</td>\n",
       "      <td>0.444</td>\n",
       "      <td>44.73</td>\n",
       "      <td>46.52</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     STATE      2016      2012    2008    2004   2000   1996  \\\n",
       "1  alabama  0.343579   0.38359  0.3874  0.3684  41.57  43.16   \n",
       "2   alaska  0.365509  0.408127  0.3789  0.3552  27.67  33.27   \n",
       "3  arizona   0.45126  0.445898  0.4512   0.444  44.73  46.52   \n",
       "\n",
       "  state_abbreviation  \n",
       "1                 AL  \n",
       "2                 AK  \n",
       "3                 AZ  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the dataframe\n",
    "states_election.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis <a class=\"anchor\" id=\"data-analysis\"></a>\n",
    "\n",
    "After the initialization with the loading and cleaning phases, we can start the data anlysis _per se_. We will first create a visualization tool to understand which feature plays an important role. Then, we will look at the geographical distribution of fake news and try to correlate it with additional data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relative importance of each feature <a class=\"anchor\" id=\"relative-importance\"></a>\n",
    "\n",
    "In order to investigate and visualize the data contained in `liar`, we can create a widget which takes as inputs each of the different metadata associated to a statement and returns as output the number of statements which have this set of metadata. This will help understanding how important every features (like profession, subject, etc.) of the statements are and also help finding interesting patterns.\n",
    "\n",
    "Before we can do that, we have to define a function which will be able to retrieve only the most relevant and occurent values for each feature. For example, for the parties, we will care about the Republicans and the Democrats but less about other minor entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_x(col_name, x, sorted=False):\n",
    "    '''\n",
    "    Returns a sorted (if needed) list of the top x entities with the most occurencies in the column specified by col_name.\n",
    "    :param col_name: str, x: int, sorted: bool\n",
    "    :return: top_ten\n",
    "    '''\n",
    "    # Get the top x\n",
    "    top_x = liar[['statement_id', col_name]].groupby(col_name)\\\n",
    "                                            .count()\\\n",
    "                                            .sort_values('statement_id', ascending=False)\\\n",
    "                                            .head(x)\\\n",
    "                                            .index\\\n",
    "                                            .values\\\n",
    "                                            .astype('str')\n",
    "    \n",
    "    # Create an array of tupple where the first element is like the second but its dashes are replaced by spaces and each word is capitalized\n",
    "    top_x = [(s.replace('-', ' ').title(), s) for s in top_x]\n",
    "    \n",
    "    # If sorted is True, sort the list by alphabetical order\n",
    "    if sorted:\n",
    "        top_x.sort(key=lambda x: x[0])\n",
    "    return top_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have everything we need in order to build our widget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the total number of statements\n",
    "nb_tot = liar.shape[0]\n",
    "\n",
    "# Replace all NaNs by 'NA' to avoid categorizing statements as excluded when they should be included\n",
    "liarNA = liar.fillna('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def lable_proportion(toggle_dots, datapoints_per_dot, label, subject, speaker, profession, state, party, context):\n",
    "    '''\n",
    "    Print the proportion of statements which have the properties specified by the inputs.\n",
    "    :param toggle_dots: bool, datapoints_per_dot: int, label-context: str\n",
    "    :return: None\n",
    "    '''\n",
    "    # In case \"All <input>\" is required, replace the corresponding input by the column it corresponds to in liarNA\n",
    "    # so that the filter wrt this input contains only \"True\" values. \n",
    "    if subject == 'all_subjects':\n",
    "        subject = liarNA.subject\n",
    "    if speaker == 'all_speakers':\n",
    "        speaker = liarNA.speaker\n",
    "    if profession == 'all_professions':\n",
    "        profession = liarNA.profession\n",
    "    if state == 'all_states':\n",
    "        state = liarNA.state\n",
    "    if party == 'all_parties':\n",
    "        party = liarNA.party\n",
    "    if context == 'all_contexts':\n",
    "        context = liarNA.context\n",
    "    \n",
    "    # Compute the filters to keep only statements having the properties specified by the inputs\n",
    "    filter_all_but_labels = (liarNA.subject==subject)       & (liarNA.speaker==speaker) & \\\n",
    "                            (liarNA.profession==profession) & (liarNA.state==state)     & \\\n",
    "                            (liarNA.party==party)           & (liarNA.context==context)\n",
    "    \n",
    "    filter_pants_on_fire = (liarNA.label=='pants-fire')  & filter_all_but_labels\n",
    "    filter_false         = (liarNA.label=='false')       & filter_all_but_labels\n",
    "    filter_barely_true   = (liarNA.label=='barely-true') & filter_all_but_labels\n",
    "    filter_half_true     = (liarNA.label=='half-true')   & filter_all_but_labels\n",
    "    filter_mostly_true   = (liarNA.label=='mostly-true') & filter_all_but_labels\n",
    "    filter_true          = (liarNA.label=='true')        & filter_all_but_labels\n",
    "    \n",
    "    # Apply the filters and count the number of remaining statements for each label.\n",
    "    if label == 'all_labels':\n",
    "        nb_pants_on_fire = round(liarNA[filter_pants_on_fire].shape[0] / datapoints_per_dot)\n",
    "        nb_false         = round(liarNA[filter_false]        .shape[0] / datapoints_per_dot)\n",
    "        nb_barely_true   = round(liarNA[filter_barely_true]  .shape[0] / datapoints_per_dot)\n",
    "        nb_half_true     = round(liarNA[filter_half_true]    .shape[0] / datapoints_per_dot)\n",
    "        nb_mostly_true   = round(liarNA[filter_mostly_true]  .shape[0] / datapoints_per_dot)\n",
    "        nb_true          = round(liarNA[filter_true]         .shape[0] / datapoints_per_dot)\n",
    "    else:\n",
    "        nb_pants_on_fire = round(liarNA[filter_pants_on_fire & (liarNA.label==label)].shape[0] / datapoints_per_dot)\n",
    "        nb_false         = round(liarNA[filter_false         & (liarNA.label==label)].shape[0] / datapoints_per_dot)\n",
    "        nb_barely_true   = round(liarNA[filter_barely_true   & (liarNA.label==label)].shape[0] / datapoints_per_dot)\n",
    "        nb_half_true     = round(liarNA[filter_half_true     & (liarNA.label==label)].shape[0] / datapoints_per_dot)\n",
    "        nb_mostly_true   = round(liarNA[filter_mostly_true   & (liarNA.label==label)].shape[0] / datapoints_per_dot)\n",
    "        nb_true          = round(liarNA[filter_true          & (liarNA.label==label)].shape[0] / datapoints_per_dot)\n",
    "    \n",
    "    # Count the number of statements which does not have the properties specified by the inputs\n",
    "    nb_others = round(nb_tot/datapoints_per_dot - (nb_pants_on_fire + nb_false + nb_barely_true +\n",
    "                                                   nb_half_true + nb_mostly_true + nb_true))\n",
    "    \n",
    "    # Print the legend\n",
    "    print('\\033[1mThere is a total of %s statements, out of which %s satisfy your requirements.\\033[0m'%(nb_tot, nb_tot-nb_others*datapoints_per_dot))\n",
    "    print('\\n\\033[41m    \\033[0m Pants on fire    ' +\n",
    "            '\\033[42m    \\033[0m False    '         +\n",
    "            '\\033[43m    \\033[0m Barely true    '   +\n",
    "            '\\033[44m    \\033[0m Half true    '     +\n",
    "            '\\033[45m    \\033[0m Mostly true    '   +\n",
    "            '\\033[46m    \\033[0m True    '          +\n",
    "            '\\033[40m    \\033[0m Excluded\\n')\n",
    "    \n",
    "    # Print colored areas proportional to the number of statements satisfying the requirements\n",
    "    if toggle_dots:# With dots\n",
    "        print('\\033[41m' + html.unescape(nb_pants_on_fire*'&#x25CF') + '\\033[0m' +\n",
    "              '\\033[42m' + html.unescape(nb_false*'&#x25CF')         + '\\033[0m' +\n",
    "              '\\033[43m' + html.unescape(nb_barely_true*'&#x25CF')   + '\\033[0m' +\n",
    "              '\\033[44m' + html.unescape(nb_half_true*'&#x25CF')     + '\\033[0m' +\n",
    "              '\\033[45m' + html.unescape(nb_mostly_true*'&#x25CF')   + '\\033[0m' +\n",
    "              '\\033[46m' + html.unescape(nb_true*'&#x25CF')          + '\\033[0m' +\n",
    "              '\\033[40m' + html.unescape(nb_others*'&#x25CF')        + '\\033[0m')\n",
    "    else:# Without dots\n",
    "        print('\\033[41m' + nb_pants_on_fire*' ' + '\\033[0m' +\n",
    "              '\\033[42m' + nb_false*' '         + '\\033[0m' +\n",
    "              '\\033[43m' + nb_barely_true*' '   + '\\033[0m' +\n",
    "              '\\033[44m' + nb_half_true*' '     + '\\033[0m' +\n",
    "              '\\033[45m' + nb_mostly_true*' '   + '\\033[0m' +\n",
    "              '\\033[46m' + nb_true*' '          + '\\033[0m' +\n",
    "              '\\033[40m' + nb_others*' '        + '\\033[0m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f4c39e43214f988b0543ba9c49133f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButton(value=False, button_style='success', description='Toggle dots', tooltip='Shâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a widget for the function above (lable_proportion)\n",
    "ipw.interact(lable_proportion,\n",
    "             toggle_dots = ipw.widgets.ToggleButton(value=False, description='Toggle dots', button_style='success', tooltip='Show/hide the dots representing each statements'),\n",
    "             datapoints_per_dot = ipw.widgets.IntSlider(value=1., min=1., max=10, description='#statements per dot', style={'description_width': 'initial'}),\n",
    "             label      = [('All labels', 'all_labels'), ('Pants on fire', 'pants-fire'),\n",
    "                           ('False', 'false'), ('Barely true', 'barely-true'),\n",
    "                           ('Half true', 'half-true'), ('Mostly true', 'mostly-true'),\n",
    "                           ('True', 'true')],\n",
    "             subject    = [('All subjects',    'all_subjects'   )] + find_top_x('subject',    10, sorted=True),\n",
    "             speaker    = [('All speakers',    'all_speakers'   )] + find_top_x('speaker',    10, sorted=False),\n",
    "             profession = [('All professions', 'all_professions')] + find_top_x('profession', 10, sorted=True),\n",
    "             state      = [('All states',      'all_states'     )] + find_top_x('state',      61, sorted=True),\n",
    "             party      = [('All parties',     'all_parties'    )] + find_top_x('party',      10, sorted=False),\n",
    "             context    = [('All contexts',    'all_contexts'   )] + find_top_x('context',    10, sorted=True));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map visualization <a class=\"anchor\" id=\"map-visualization\"></a>\n",
    "\n",
    "As we have information concerning where each statement was made, we can visualize their distribution geographically on a map. This will allow us to determine whether there are states where politicians tend to lie more. These states (if any) would be more vulnerable to potentially harmful consequences of fake news and thus identifying them is an important task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the geo json file to display the states\n",
    "states_geo_json = json.load(open(DATA_DIR + r'us-states.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_map_label(label):\n",
    "    '''\n",
    "    Plots a map of the USA indicating the number of statements per states for a selected label.\n",
    "    :param label: str\n",
    "    :return: None\n",
    "    '''\n",
    "    # Filter out all statements with labels different from label\n",
    "    filter_label = liar.label == label\n",
    "    \n",
    "    # Count the number of remaining statements per state\n",
    "    state_count = liar[filter_label].groupby('state_abbreviation')\\\n",
    "                                    .count()\\\n",
    "                                    .reset_index()\\\n",
    "                                    .filter(['state_abbreviation', 'statement_id'])\n",
    "    \n",
    "    # Add the states where no statements were made (so that they do not appear with the darkest color on the map)\n",
    "    for state in states_abbreviation['Abbreviation']:\n",
    "        if not liar[filter_label]['state_abbreviation'].str.contains(state, regex=False).any():\n",
    "            state_count = state_count.append(pd.DataFrame([(state, 0)],\n",
    "                                             columns=['state_abbreviation', 'statement_id']))\n",
    "    \n",
    "    # Create a map centered around the USA\n",
    "    m_usa = folium.Map([43,-100], tiles='cartodbpositron', zoom_start=4)\n",
    "    \n",
    "    # Add a filter to the map indicating the number of statements in each state\n",
    "    m_usa.choropleth(geo_data=states_geo_json, data=state_count,\n",
    "                    columns=['state_abbreviation', 'statement_id'],\n",
    "                    key_on='feature.id',\n",
    "                    fill_color='YlOrRd', fill_opacity=0.7, line_opacity=1,\n",
    "                    legend_name=('Number of %s statements in each state'%label),\n",
    "                    highlight=True)\n",
    "    \n",
    "    # Display the map\n",
    "    display(m_usa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to just visualizing the number of statements per state, we can also compare the results with the data contained in the two additional datasets which we loaded earlier, `pop-urban-pct-historical.xls` and `federalelections2016.xlsx`. For that, we will display another map right below the previous one in order to allow a direct comparison between the two maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_map_comparison(select_data):\n",
    "    '''\n",
    "    Plots a map of the USA with either information on urbanity or elections outcome.\n",
    "    :param select_data: str\n",
    "    :return: None\n",
    "    '''\n",
    "    # Select the right dataset\n",
    "    if select_data[0:-4] == 'urb_':\n",
    "        data = states_urban.filter(['state_abbreviation', int(select_data[-4:])])\n",
    "    if select_data[0:-4] == 'elec_':\n",
    "        data = states_election.filter(['state_abbreviation', int(select_data[-4:])])\n",
    "    \n",
    "    # Create a map centered around the USA\n",
    "    m_usa = folium.Map([43,-100], tiles='cartodbpositron', zoom_start=4)\n",
    "    \n",
    "    # Add a filter to the map indicating the required data\n",
    "    m_usa.choropleth(geo_data=states_geo_json, data=data,\n",
    "                    columns=['state_abbreviation', int(select_data[-4:])],\n",
    "                    key_on='feature.id',\n",
    "                    fill_color='RdBu', fill_opacity=0.7, line_opacity=1,\n",
    "                    legend_name=('Number of %s statements in each state'%select_data),\n",
    "                    highlight=True)\n",
    "    \n",
    "    # Display the map\n",
    "    display(m_usa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d7e9c9295664922a5bf332d7a78c2e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='label', options=(('Pants on fire', 'pants-fire'), ('False', 'falseâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98a545471b3e4ea98e4f1c44444a68b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='select_data', options=(('Urban percentage 2010', 'urb_2010'), ('Urâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a widget for the function plot_map_label\n",
    "ipw.interact(plot_map_label, label=[('Pants on fire', 'pants-fire'), ('False', 'false'), ('Barely true', 'barely-true'),\n",
    "                           ('Half true', 'half-true'), ('Mostly true', 'mostly-true'), ('True', 'true')]);\n",
    "\n",
    "# Create a widget for the function plot_map_comparison\n",
    "ipw.interact(plot_map_comparison, select_data=[('Urban percentage 2010', 'urb_2010'), ('Urban percentage 2000', 'urb_2010'),\n",
    "                                               ('Election 2016', 'elec_2016'), ('Election 2012', 'elec_2012'),\n",
    "                                               ('Election 2008', 'elec_2008'), ('Election 2004', 'elec_2004'),\n",
    "                                               ('Election 2000', 'elec_2000'), ('Election 2096', 'elec_2096')]);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
